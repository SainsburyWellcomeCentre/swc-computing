---
name: HPC documentation request
about: Request documentation for a specific HPC task at SWC/Gatsby.
title: "[DOCS REQUEST]"
labels: documentation
assignees: ''

---

## Task description
<!-- Provide a detailed, specific example of what you need to accomplish on the HPC resources at SWC/Gatsby. The more specific, the better! For example: -->
<!-- "I need to know how to..." -->
<!-- - request 4 A100 GPUs with 80GB memory each for a single PyTorch distributed training job. -->
<!-- - set up a Conda environment with CUDA 11.7 and PyTorch 2.0 that persists across jobs. -->
<!-- - decide which filesystem to use to store my training logs. -->
<!-- - transfer a 500GB dataset from my local machine to the cluster's /scratch directory using rsync. -->
<!-- - debug why my job with 64GB memory request is stuck in the queue for over 24 hours. -->
<!-- - use Slurm's array jobs to run a hyperparameter sweep with 100 different configurations of my JAX model. -->

## Required resources
<!-- List the SWC/Gatsby HPC resources this task needs. For example: -->
<!-- - Compute nodes (type and number): -->
<!-- - GPUs (type, number, and memory): -->
<!-- - Storage system and space needed: -->
<!-- - Required software or modules: -->

## Current approach
<!-- Summarize what you've already tried. Include: -->
<!-- - Steps you've taken so far -->
<!-- - Command(s) or script(s) you're using (provide actual code if possible) -->
<!-- - Current outcome of your approach -->

## Issues encountered
<!-- Describe any problems or errors you're facing. Consider: -->
<!-- - What errors or unexpected results are you seeing? -->
<!-- - At which step do these issues occur? -->

## Additional context
<!-- Add any other relevant information, such as: -->
<!-- - Any time constraints or performance requirements -->
<!-- - Related tasks or workflows this is part of -->
<!-- - Which users/groups at SWC/Gatsby might benefit from this tutorial -->
